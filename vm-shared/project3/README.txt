Project 4 - Task 4 (optional improvement)

The goal of Task 4 is to improve a spellchecker program. Current method (from Task 1 to Task 3) made a lot of simple assumptions, however, it does an exceptional job at predicting up to 74.34% correct in the given corpus. With the current improvement in task 4, I was able to get up to 80% with a few additional assumptions.

The first assumption was made in the EditDist1 function. Previously, we are required to only swap two adjacement characters in Damerau-Levenshtein distance, however, I felt this is limited since it could potentially miss out other generated candidates. I modified the substitution part to swap not just two adjacement characters but all characters. This seems to help with the generateCandidates function but it's a brute force and might not be an ideal assumption for speed. Given more time, this is definitely an area that can be improved on.

Other assumptions were made in the Error Model function. The first assumption was to remove all the vowels in the word and correction variables (except the first letter since the first letter dictates a word). I compare the length and position of removed vowels for  the word and correction. If the length and character of the position are exactly the same, then I assume that the words have a high  probability that the are the same word. I also check for the original word and correction length and penalize about 15% per character difference. I found that penalizing too much (greater than 30%) would actually decrease the matching, or penalizing too little (less than 10%) would not help either. To penalize this, I used the root factor and I found it to work well in this model. If both of these checks are good, then I can safely assume that these are the higher and return an infitely large EMResult (I use double.MAX_VALUE). The reason why I used an infitely big number is because I have a higher probability of predicting the word and want to overcome the P(word) probability.

The second assumption in Error Model function is if the removed vowels word and correction are not the same, then it's going to count the number of matching letters instead. If the last letter ends with a 'y', it will check for the previous letter 'l'. It will give a small score booster because this is for any adverbs that end with a -ly. Same thing for 'ed' (past tensed and adjective), 'ng' (present participle), 've' (adjective).

Overall, the main goal of this optional improvment is to see whether spellchecker can be improved, in this case, by removing vowels in the words, and it seems it increase by 6% using the provided corpus. Although it only uses fundamental assumptions, this area can be definitely improved upon if given extra time to research. I am looking into how syllables can also affect how the user inputs the word. Typically, users sound out the word before they input the query. If we're able to capture the number of syllables, we can better compare the word and correction, and penalize if the number of syllables are the same. The difficult part is to overcome the typical 'silent' syllables in the English language, and that syllables are somewhat based on 'human judgement'.

